import os
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv() # Load environment variables from .env file
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

class Model:
    # H√†m kh·ªüi t·∫°o: H√†m set up m√¥ h√¨nh (model)
    def __init__(self, model_id: str = "gemini-1.5-pro"):
        self.model_id = model_id

        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY is not set. Check your .env file.")

        # Configure Gemini API
        genai.configure(api_key=GEMINI_API_KEY)
        print("Gemini API configured successfully.")

        # Generation and safety configuration
        self.generation_config = {
            "temperature": 0,
            "top_p": 0.95,
            "top_k": 64,
            "max_output_tokens": 8192,
            "response_mime_type": "text/plain",
        }

        self.safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        ]

    # H√†m truy v·∫•n API: H√†m g·ª≠i y√™u c·∫ßu t·ªõi API ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi
    def query_gemini_api(self, system_instruction: str):
        model = genai.GenerativeModel(
            model_name=self.model_id,
            safety_settings=self.safety_settings,
            generation_config=self.generation_config,
            system_instruction=system_instruction,
        )
        return model.start_chat(history=[])

    # H√†m t·∫°o c√¢u tr·∫£ l·ªùi: H√†m t·∫°o c√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
    def generate(self, question: str, context: str = None):
        # Prepare the prompt
        if not context:
            prompt = f"Question: {question}"
        else:
            prompt = f"Context: {context}\nQuestion: {question}"

        # Define system instruction
        system_instruction = (
            "B·∫°n l√† m·ªôt ng∆∞·ªùi t∆∞ v·∫•n th√¥ng tin cho C√¢u L·∫°c B·ªô (CLB). Nhi·ªám v·ª• c·ªßa b·∫°n l√† h·ªó tr·ª£ ng∆∞·ªùi d√πng t√¨m hi·ªÉu, cung c·∫•p th√¥ng tin, "
            "ph√¢n t√≠ch v√† gi·∫£i ƒë√°p c√°c th·∫Øc m·∫Øc li√™n quan ƒë·∫øn CLB. H√£y cung c·∫•p c√¢u tr·∫£ l·ªùi r√µ r√†ng, chi ti·∫øt v√† d·ªÖ hi·ªÉu k√®m c√°c v√≠ d·ª• th·ª±c t·∫ø "
            "(n·∫øu c·∫ßn) ƒë·ªÉ gi√∫p ng∆∞·ªùi d√πng n·∫Øm ƒë∆∞·ª£c m·ª•c ƒë√≠ch, ho·∫°t ƒë·ªông v√† c√°c th√¥ng tin h·ªØu √≠ch kh√°c c·ªßa CLB. Kh√¥ng tr·∫£ l·ªùi nh·ªØng th√¥ng tin ngo√†i"
        )

        # Query Gemini API: G·ª≠i request t·ªõi API ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi
        chat_session = self.query_gemini_api(system_instruction=system_instruction)

        # Nh·∫≠n response t·ª´ API
        response = chat_session.send_message(prompt)

        return response.text

def main():
    try:
        model = Model(model_id="gemini-1.5-pro")
    except ValueError as e:
        print(f"Error: {e}")
        return
    
    print("‚úÖ Model ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng!")
    
    print("\nüí¨ Chat Bot: H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n. G√µ 'exit' ƒë·ªÉ tho√°t.")
    
    while True:
        user_input = input("B·∫°n: ")
        
        if user_input.lower() == "exit":
            print("üëã T·∫°m bi·ªát! H·∫πn g·∫∑p l·∫°i.")
            break
        
        try:
            answer = model.generate(question=user_input, context=None)
            print(f"\nü§ñ Chat Bot:\n{answer}\n")
        except Exception as e:
            print(f"‚ùå ƒê√£ x·∫£y ra l·ªói khi g·ªçi Gemini API: {e}")

if __name__ == "__main__":
    main()