import os
import google.generativeai as genai
from dotenv import load_dotenv

def initialize_model(model_id: str = "gemini-1.5-pro"):
    """H√†m kh·ªüi t·∫°o v√† tr·∫£ v·ªÅ ƒë·ªëi t∆∞·ª£ng model ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh."""
    load_dotenv()  # Load environment variables from .env file
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

    if not GEMINI_API_KEY:
        raise ValueError("GEMINI_API_KEY is not set. Check your .env file.")

    # Configure Gemini API
    genai.configure(api_key=GEMINI_API_KEY)
    print("Gemini API configured successfully.")

    # Generation and safety configuration
    generation_config = {
        "temperature": 0,
        "top_p": 0.95,
        "top_k": 64,
        "max_output_tokens": 8192,
        "response_mime_type": "text/plain",
    }

    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    ]

    def query_gemini_api(system_instruction: str):
        """H√†m g·ª≠i y√™u c·∫ßu t·ªõi Gemini API ƒë·ªÉ b·∫Øt ƒë·∫ßu phi√™n tr√≤ chuy·ªán."""
        model = genai.GenerativeModel(
            model_name=model_id,
            safety_settings=safety_settings,
            generation_config=generation_config,
            system_instruction=system_instruction,
        )
        return model.start_chat(history=[])

    def generate(question: str, context: str = None):
        """H√†m t·∫°o c√¢u tr·∫£ l·ªùi d·ª±a tr√™n c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng."""
        # Prepare the prompt
        if not context:
            prompt = f"Question: {question}"
        else:
            prompt = f"Only reply to content within context: {context}\nQuestion: {question}"

        # Define system instruction
        system_instruction = (
            "B·∫°n l√† m·ªôt chatbot t∆∞ v·∫•n th√¥ng tin v·ªÅ c√°c ƒë·ªãa ƒëi·ªÉm t·∫°i Vi·ªát Nam. Nhi·ªám v·ª• c·ªßa b·∫°n l√† cung c·∫•p th√¥ng tin, "
            "gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ c√°c ƒë·ªãa danh, vƒÉn h√≥a, l·ªãch s·ª≠ v√† c√°c th√¥ng tin h·ªØu √≠ch kh√°c t·∫°i c√°c t·ªânh th√†nh ·ªü Vi·ªát Nam. "
            "H√£y ƒë∆∞a ra c√¢u tr·∫£ l·ªùi chi ti·∫øt, ch√≠nh x√°c v√† d·ªÖ hi·ªÉu ƒë·ªÉ gi√∫p ng∆∞·ªùi d√πng kh√°m ph√° Vi·ªát Nam m·ªôt c√°ch t·ªët nh·∫•t. "
            "Kh√¥ng tr·∫£ l·ªùi nh·ªØng th√¥ng tin kh√¥ng li√™n quan ƒë·∫øn ƒë·ªãa ƒëi·ªÉm t·∫°i Vi·ªát Nam."
        )

        # Query Gemini API: G·ª≠i request t·ªõi API ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi
        chat_session = query_gemini_api(system_instruction=system_instruction)

        # Nh·∫≠n response t·ª´ API
        response = chat_session.send_message(prompt)

        return response.text

    return generate

def chat_with_model():
    """H√†m ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi ng∆∞·ªùi d√πng qua giao di·ªán console."""
    try:
        generate_response = initialize_model(model_id="gemini-1.5-pro")
    except ValueError as e:
        print(f"Error: {e}")
        return

    print("\n‚úÖ Model ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng!")
    print("\nüí¨ Chat Bot: H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n. G√µ 'exit' ƒë·ªÉ tho√°t.")

    while True:
        user_input = input("B·∫°n: ")

        if user_input.lower() == "exit":
            print("üëã T·∫°m bi·ªát! H·∫πn g·∫∑p l·∫°i.")
            break

        try:
            answer = generate_response(question=user_input, context=None)
            print(f"\nü§ñ Chat Bot:\n{answer}\n")
        except Exception as e:
            print(f"‚ùå ƒê√£ x·∫£y ra l·ªói khi g·ªçi Gemini API: {e}")

if __name__ == "__main__":
    chat_with_model()
